{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355efd46-0fe2-482c-b0cc-a5bd1ceef3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install transformers datasets rouge-score scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f29c47-43d1-4990-a9aa-31b6c0a75ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer, Trainer, TrainingArguments\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bc9da7-7c6a-4c82-8679-c141f78a3afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Preprocess Datasets\n",
    "\n",
    "def load_pubmed_dataset():\n",
    "    \"\"\"Loads the PubMed dataset from Hugging Face.\"\"\"\n",
    "    pubmed_dataset = load_dataset(\"ccdv/pubmed-summarization\", \"section\")\n",
    "    return pubmed_dataset\n",
    "\n",
    "def load_arxiv_dataset():\n",
    "    \"\"\"Loads the arXiv dataset from Hugging Face.\"\"\"\n",
    "    arxiv_dataset = load_dataset(\"ccdv/arxiv-summarization\")  \n",
    "    return arxiv_dataset\n",
    "\n",
    "def preprocess_data(pubmed_dataset, arxiv_dataset):\n",
    "    \"\"\"Combines PubMed and arXiv datasets and renames columns.\"\"\"\n",
    "    combined_dataset = concatenate_datasets([pubmed_dataset[\"train\"], arxiv_dataset[\"train\"]])\n",
    "    combined_dataset = combined_dataset.rename_column(\"article\", \"text\")\n",
    "    combined_dataset = combined_dataset.rename_column(\"abstract\", \"summary\")\n",
    "    return combined_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512309e1-eda8-4e0a-b4b3-64cf6fb67650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the Model\n",
    "\n",
    "def train_model(train_dataset, val_dataset):\n",
    "    \"\"\"Trains the BART model using the provided training and validation datasets.\"\"\"\n",
    "    model_name = \"facebook/bart-large-cnn\"\n",
    "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "    model = BartForConditionalGeneration.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375f28e2-fadd-44c1-8a62-3a27210fc3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def tokenize_data(examples):\n",
    "        \"\"\"Tokenizes the input text and summary using the BART tokenizer.\"\"\"\n",
    "        inputs = tokenizer(examples[\"text\"], max_length=1024, truncation=True, padding=\"max_length\")\n",
    "        targets = tokenizer(examples[\"summary\"], max_length=128, truncation=True, padding=\"max_length\")\n",
    "        inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "        return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef46ddbd-7d5d-4b43-8ffb-b482e40afcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "  train_dataset = train_dataset.map(tokenize_data, batched=True)\n",
    "    val_dataset = val_dataset.map(tokenize_data, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fb7924-f4b0-43a9-935a-d1cb76371ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        per_device_train_batch_size=2,  \n",
    "        per_device_eval_batch_size=2,   \n",
    "        num_train_epochs=2,             \n",
    "        evaluation_strategy=\"epoch\",\n",
    "        logging_dir=\"./logs\",\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab5b7e-c8f2-4803-aede-21a9959ca75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "   trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4546933-ebaa-4593-8bbc-0af44d9e94c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Save the PyTorch model as a pickle file\n",
    "    torch.save(model.state_dict(), 'summarization_model.pkl') \n",
    "\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c326a9-2d61-437d-8641-1323b6fef854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Evaluate on Test Dataset\n",
    "\n",
    "def evaluate_model(model, tokenizer, test_dataset):\n",
    "    \"\"\"Evaluates the trained model using the ROUGE metric.\"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'])\n",
    "    results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0357ba-fd5e-4c6f-a91b-0ac1ad012ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    " for example in test_dataset:\n",
    "        text = example[\"text\"]\n",
    "        reference_summary = example[\"summary\"]\n",
    "\n",
    "        # Generate summary\n",
    "        inputs = tokenizer([text], max_length=1024, return_tensors=\"pt\", truncation=True)\n",
    "        summary_ids = model.generate(inputs[\"input_ids\"], max_length=128, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
    "        generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ac485-ef3d-4e78-8bfa-3294dc57bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROUGE scores\n",
    "        scores = scorer.score(reference_summary, generated_summary)\n",
    "        results.append({\n",
    "            \"ROUGE-1\": scores[\"rouge1\"].fmeasure,\n",
    "            \"ROUGE-2\": scores[\"rouge2\"].fmeasure,\n",
    "            \"ROUGE-L\": scores[\"rougeL\"].fmeasure,\n",
    "        })\n",
    "\n",
    "    # Aggregate results\n",
    "    avg_rouge1 = sum(r[\"ROUGE-1\"] for r in results) / len(results)\n",
    "    avg_rouge2 = sum(r[\"ROUGE-2\"] for r in results) / len(results)\n",
    "    avg_rougeL = sum(r[\"ROUGE-L\"] for r in results) / len(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9319c79d-3f33-439b-b52a-e1f7a83b0da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(f\"Average ROUGE-1: {avg_rouge1}\")\n",
    "    print(f\"Average ROUGE-2: {avg_rouge2}\")\n",
    "    print(f\"Average ROUGE-L: {avg_rougeL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41f6ab2-9833-4b96-accb-dedbcced1ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Execution\n",
    "\n",
    "if _name_ == \"_main_\":\n",
    "    # Load datasets\n",
    "    pubmed_dataset = load_pubmed_dataset()\n",
    "    arxiv_dataset = load_arxiv_dataset()\n",
    "\n",
    "    # Preprocess data\n",
    "    train_val_dataset = preprocess_data(pubmed_dataset, arxiv_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f849d4e3-4ede-4e64-aebf-96c08d234b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Implement k-fold cross-validation and select one fold\n",
    "    k = 5  # Number of folds (adjust as needed)\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42) \n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(train_val_dataset)):\n",
    "        print(f\"Training on fold {fold + 1}...\")\n",
    "        train_dataset = train_val_dataset.select(train_index)\n",
    "        val_dataset = train_val_dataset.select(val_index)\n",
    "        \n",
    "        # Train and evaluate only on the first fold to reduce dataset size\n",
    "        if fold == 0:\n",
    "            model, tokenizer = train_model(train_dataset, val_dataset)\n",
    "            \n",
    "            # Load and evaluate on the test dataset (CompScholar)\n",
    "            compscholar_df = pd.read_csv(\"Brain Dead CompScholar Dataset.csv\")\n",
    "            test_dataset = Dataset.from_pandas(compscholar_df)\n",
    "            evaluate_model(model, tokenizer, test_dataset)\n",
    "            \n",
    "            break  # Stop after the first fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff46ae-8a1e-4129-8889-a18d4dba50c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
